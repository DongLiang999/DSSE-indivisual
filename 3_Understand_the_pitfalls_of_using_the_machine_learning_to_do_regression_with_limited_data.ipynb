{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Understand the pitfalls of using the machine learning to do regression with limited data"
      ],
      "metadata": {
        "id": "7hgwTCfUXmCh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Background"
      ],
      "metadata": {
        "id": "5eYGNEK2Xnya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Currently, I only know the basic concept of machine learning, but at the end of this course, I will be able to explain the pitfalls of doing regression with machine learning and how it will affect the result of regression.\n",
        "\n",
        "I will demonstrate this in a small essay in which I will provide a literature review about the limitation of machine learning and an analysis of our project procedure to show how machine learning is used and the pros and cons of using it in our project.\n",
        "\n",
        "**Note**: This goal is based on my process of achieving the second goal."
      ],
      "metadata": {
        "id": "OU1EFdkTYFLx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Details about the implementation"
      ],
      "metadata": {
        "id": "dqpifP23Xzii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Limitations of machine learning in regression with limited data"
      ],
      "metadata": {
        "id": "s6eeN28tYJWj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Limited data I mentioned here means that the number of instances in the dataset is insufficient or relatively small. And in my case of using machine learning in multiple linear regression, limited data also means a limited historical record because the dataset may have time series features.\n",
        "\n",
        "There are several common issues caused by limited data in machine learning.\n",
        "\n",
        "First, overfitting is the use of models or procedures that violate parsimony that is, that include more terms than are necessary or use more complicated approaches than are necessary. (Hawkins, 2004) Generally, a small dataset may have higher risk of overfitting. My dataset is exactly a small one.\n",
        "\n",
        "Using a model which is too flexible can cause overfitting. In my case, I assume that the data has linear relationship and it could be fitted by LinearSVR (Support Vector Regression) and RandomForestRegressor. But comparing with LinearRegression model, these two models are much more flexible. LinearSVR assumes a linear relationship, but it introduces support vectors. It is flexible in capturing non-linear relationship. RandomForestRegressor can also capture complex non-linear relationships and interactions between features (Auret & Aldrich, 2012).\n",
        "\n",
        "Including unrelated components in features can also cause overfitting. In my case, I include number of transactions and vehicles as independent variables. They must have relationship with emission from road transport. So, this may not be the cause of overfitting.\n",
        "\n",
        "Second, underfitting occurs when a model is too simple, which can be a result of a model needing more training time, more input features, or less regularization.(IBM, n.d.) In my case, the relationship between traffic and emissions can be effected by other features. That is to say, there can be some unknown factors that can influence the amount of emission, for example, temperature, wind, precipitation and so on. This may lead to a model which is not expressive enough to capture the real world. RandomForestRegressor and LinearSVR both got higher MSE(Mean Squared Error) during model evaluation. It can be caused by underfitting.\n",
        "\n",
        "Third, dividing a small dataset into training, validation, and test sets may lead to subsets that can't fully represent the underlying data distribution. It can affect the reliability of model evaluation metrics.(Hastie, Tibshirani & Friedman, 2009) In my case, the dataset is relatively small, it only has 16 rows and 6 columns. Even though I used train_test_split to divide the dataset, it is still not enough for a robust model fitting. Then the model evaluation metrics could be unreliable or even meaningless.\n",
        "\n",
        "Although there some problems with machine learning when being applied on limited data. There are still some advantages to use it in our project. If the data is not linear relationship and more features are included, machine learning models, especially more advanced ones, can capture complex relationships between variables. And many machine learning models can automatically handle feature selection, identifying which variables contribute the most to the predictive power of the model. We have taken advantage of this to investigate the most significant factors that effect NOx air pollution."
      ],
      "metadata": {
        "id": "81szHf7KYJuh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "2gUQLe5hX0ej"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The application of machine learning to a limited dataset in multiple linear regression has some challenges such as overfitting, underfitting, and potential problems with data representation in training, validation, and test sets.\n",
        "\n",
        "The risk of overfitting may arise due to the limited dataset, especially when applying more flexible models like LinearSVR and RandomForestRegressor. Underfitting may occur when the model is too simple and can not capture all the relevant features. Additionally, small datasets can lead to lower reliability of model evaluation metrics.\n",
        "\n",
        "Despite these challenges, machine learning still has advantages, particularly in capturing complex relationships and automating feature selection. In the our case of investigating factors influencing NOx air pollution, machine learning has been proven valuable in finding out significant factors even with relatively limited data."
      ],
      "metadata": {
        "id": "AtZIoUj6YKUZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusions both on the results as well as on the accomplishment of the goal"
      ],
      "metadata": {
        "id": "QGEzjroLX4IB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have successfully elaborated the limitation of machine learning when being applied on a limited dataset in multiple linear regression, which achieves my expected goal.\n",
        "\n",
        "Before, I only know the basic concept of machine learning. Now, I can explain the pros and cons of doing regression with different algorithms of machine learning. I think I have finished this goal.\n",
        "\n",
        "There are still many things I don't know about the application and result analysis of machine learning. If I had more time, I would study in depth the evaluation of model fitting results of deep learning, and learn how to choose an appropriate algorithm for a specific data set."
      ],
      "metadata": {
        "id": "rSz_1lCDAbia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reference\n",
        "\n",
        "Hawkins, D. M. (2004). The problem of overfitting. Journal of chemical information and computer sciences, 44(1), 1-12.\n",
        "\n",
        "Auret, L., & Aldrich, C. (2012). Interpretation of nonlinear relationships between process variables by use of random forests. Minerals Engineering, 35, 27-42.\n",
        "\n",
        "IBM. (n.d.). What is underfitting? Retrieved February 1, 2024, from https://www.ibm.com/topics/underfitting\n",
        "\n",
        "Hastie, T., Tibshirani, R., & Friedman, J. (2009). The Elements of Statistical Learning: Data Mining, Inference, and Prediction, 2nd edition. Springer. https://doi.org/10.1007/978-0-387-84858-6"
      ],
      "metadata": {
        "id": "ebb7sQUKYT0o"
      }
    }
  ]
}